{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "/usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/dtypes.py:521: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/dtypes.py:522: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/dtypes.py:523: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/dtypes.py:528: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "def warn(*args, **kwargs):\n",
    "    pass\n",
    "import warnings\n",
    "warnings.warn = warn\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "import sklearn\n",
    "from glob import glob\n",
    "from tqdm import tqdm\n",
    "import pickle, json\n",
    "import os\n",
    "from random import shuffle\n",
    "from matplotlib import pyplot as plt\n",
    "from scipy.spatial import distance\n",
    "from sklearn.cluster import DBSCAN\n",
    "from tqdm import tqdm\n",
    "from datetime import datetime\n",
    "import pandas as pd\n",
    "from itertools import cycle\n",
    "from time import time\n",
    "\n",
    "from sklearn.metrics import precision_recall_curve\n",
    "from sklearn.metrics import average_precision_score\n",
    "\n",
    "from keras.applications.mobilenet import MobileNet\n",
    "from keras.models import Model, Sequential, load_model as K_load_model\n",
    "from keras.layers import LSTM, Dense, InputLayer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "mb_clr = MobileNet(weights=None, input_shape=(224,224,3), classes=2)\n",
    "mb_bnw = MobileNet(weights=None, input_shape=(224,224,1), classes=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_3 (InputLayer)         (None, 224, 224, 1)       0         \n",
      "_________________________________________________________________\n",
      "conv1_pad (ZeroPadding2D)    (None, 226, 226, 1)       0         \n",
      "_________________________________________________________________\n",
      "conv1 (Conv2D)               (None, 112, 112, 32)      288       \n",
      "_________________________________________________________________\n",
      "conv1_bn (BatchNormalization (None, 112, 112, 32)      128       \n",
      "_________________________________________________________________\n",
      "conv1_relu (Activation)      (None, 112, 112, 32)      0         \n",
      "_________________________________________________________________\n",
      "conv_pad_1 (ZeroPadding2D)   (None, 114, 114, 32)      0         \n",
      "_________________________________________________________________\n",
      "conv_dw_1 (DepthwiseConv2D)  (None, 112, 112, 32)      288       \n",
      "_________________________________________________________________\n",
      "conv_dw_1_bn (BatchNormaliza (None, 112, 112, 32)      128       \n",
      "_________________________________________________________________\n",
      "conv_dw_1_relu (Activation)  (None, 112, 112, 32)      0         \n",
      "_________________________________________________________________\n",
      "conv_pw_1 (Conv2D)           (None, 112, 112, 64)      2048      \n",
      "_________________________________________________________________\n",
      "conv_pw_1_bn (BatchNormaliza (None, 112, 112, 64)      256       \n",
      "_________________________________________________________________\n",
      "conv_pw_1_relu (Activation)  (None, 112, 112, 64)      0         \n",
      "_________________________________________________________________\n",
      "conv_pad_2 (ZeroPadding2D)   (None, 114, 114, 64)      0         \n",
      "_________________________________________________________________\n",
      "conv_dw_2 (DepthwiseConv2D)  (None, 56, 56, 64)        576       \n",
      "_________________________________________________________________\n",
      "conv_dw_2_bn (BatchNormaliza (None, 56, 56, 64)        256       \n",
      "_________________________________________________________________\n",
      "conv_dw_2_relu (Activation)  (None, 56, 56, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv_pw_2 (Conv2D)           (None, 56, 56, 128)       8192      \n",
      "_________________________________________________________________\n",
      "conv_pw_2_bn (BatchNormaliza (None, 56, 56, 128)       512       \n",
      "_________________________________________________________________\n",
      "conv_pw_2_relu (Activation)  (None, 56, 56, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv_pad_3 (ZeroPadding2D)   (None, 58, 58, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv_dw_3 (DepthwiseConv2D)  (None, 56, 56, 128)       1152      \n",
      "_________________________________________________________________\n",
      "conv_dw_3_bn (BatchNormaliza (None, 56, 56, 128)       512       \n",
      "_________________________________________________________________\n",
      "conv_dw_3_relu (Activation)  (None, 56, 56, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv_pw_3 (Conv2D)           (None, 56, 56, 128)       16384     \n",
      "_________________________________________________________________\n",
      "conv_pw_3_bn (BatchNormaliza (None, 56, 56, 128)       512       \n",
      "_________________________________________________________________\n",
      "conv_pw_3_relu (Activation)  (None, 56, 56, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv_pad_4 (ZeroPadding2D)   (None, 58, 58, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv_dw_4 (DepthwiseConv2D)  (None, 28, 28, 128)       1152      \n",
      "_________________________________________________________________\n",
      "conv_dw_4_bn (BatchNormaliza (None, 28, 28, 128)       512       \n",
      "_________________________________________________________________\n",
      "conv_dw_4_relu (Activation)  (None, 28, 28, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv_pw_4 (Conv2D)           (None, 28, 28, 256)       32768     \n",
      "_________________________________________________________________\n",
      "conv_pw_4_bn (BatchNormaliza (None, 28, 28, 256)       1024      \n",
      "_________________________________________________________________\n",
      "conv_pw_4_relu (Activation)  (None, 28, 28, 256)       0         \n",
      "_________________________________________________________________\n",
      "conv_pad_5 (ZeroPadding2D)   (None, 30, 30, 256)       0         \n",
      "_________________________________________________________________\n",
      "conv_dw_5 (DepthwiseConv2D)  (None, 28, 28, 256)       2304      \n",
      "_________________________________________________________________\n",
      "conv_dw_5_bn (BatchNormaliza (None, 28, 28, 256)       1024      \n",
      "_________________________________________________________________\n",
      "conv_dw_5_relu (Activation)  (None, 28, 28, 256)       0         \n",
      "_________________________________________________________________\n",
      "conv_pw_5 (Conv2D)           (None, 28, 28, 256)       65536     \n",
      "_________________________________________________________________\n",
      "conv_pw_5_bn (BatchNormaliza (None, 28, 28, 256)       1024      \n",
      "_________________________________________________________________\n",
      "conv_pw_5_relu (Activation)  (None, 28, 28, 256)       0         \n",
      "_________________________________________________________________\n",
      "conv_pad_6 (ZeroPadding2D)   (None, 30, 30, 256)       0         \n",
      "_________________________________________________________________\n",
      "conv_dw_6 (DepthwiseConv2D)  (None, 14, 14, 256)       2304      \n",
      "_________________________________________________________________\n",
      "conv_dw_6_bn (BatchNormaliza (None, 14, 14, 256)       1024      \n",
      "_________________________________________________________________\n",
      "conv_dw_6_relu (Activation)  (None, 14, 14, 256)       0         \n",
      "_________________________________________________________________\n",
      "conv_pw_6 (Conv2D)           (None, 14, 14, 512)       131072    \n",
      "_________________________________________________________________\n",
      "conv_pw_6_bn (BatchNormaliza (None, 14, 14, 512)       2048      \n",
      "_________________________________________________________________\n",
      "conv_pw_6_relu (Activation)  (None, 14, 14, 512)       0         \n",
      "_________________________________________________________________\n",
      "conv_pad_7 (ZeroPadding2D)   (None, 16, 16, 512)       0         \n",
      "_________________________________________________________________\n",
      "conv_dw_7 (DepthwiseConv2D)  (None, 14, 14, 512)       4608      \n",
      "_________________________________________________________________\n",
      "conv_dw_7_bn (BatchNormaliza (None, 14, 14, 512)       2048      \n",
      "_________________________________________________________________\n",
      "conv_dw_7_relu (Activation)  (None, 14, 14, 512)       0         \n",
      "_________________________________________________________________\n",
      "conv_pw_7 (Conv2D)           (None, 14, 14, 512)       262144    \n",
      "_________________________________________________________________\n",
      "conv_pw_7_bn (BatchNormaliza (None, 14, 14, 512)       2048      \n",
      "_________________________________________________________________\n",
      "conv_pw_7_relu (Activation)  (None, 14, 14, 512)       0         \n",
      "_________________________________________________________________\n",
      "conv_pad_8 (ZeroPadding2D)   (None, 16, 16, 512)       0         \n",
      "_________________________________________________________________\n",
      "conv_dw_8 (DepthwiseConv2D)  (None, 14, 14, 512)       4608      \n",
      "_________________________________________________________________\n",
      "conv_dw_8_bn (BatchNormaliza (None, 14, 14, 512)       2048      \n",
      "_________________________________________________________________\n",
      "conv_dw_8_relu (Activation)  (None, 14, 14, 512)       0         \n",
      "_________________________________________________________________\n",
      "conv_pw_8 (Conv2D)           (None, 14, 14, 512)       262144    \n",
      "_________________________________________________________________\n",
      "conv_pw_8_bn (BatchNormaliza (None, 14, 14, 512)       2048      \n",
      "_________________________________________________________________\n",
      "conv_pw_8_relu (Activation)  (None, 14, 14, 512)       0         \n",
      "_________________________________________________________________\n",
      "conv_pad_9 (ZeroPadding2D)   (None, 16, 16, 512)       0         \n",
      "_________________________________________________________________\n",
      "conv_dw_9 (DepthwiseConv2D)  (None, 14, 14, 512)       4608      \n",
      "_________________________________________________________________\n",
      "conv_dw_9_bn (BatchNormaliza (None, 14, 14, 512)       2048      \n",
      "_________________________________________________________________\n",
      "conv_dw_9_relu (Activation)  (None, 14, 14, 512)       0         \n",
      "_________________________________________________________________\n",
      "conv_pw_9 (Conv2D)           (None, 14, 14, 512)       262144    \n",
      "_________________________________________________________________\n",
      "conv_pw_9_bn (BatchNormaliza (None, 14, 14, 512)       2048      \n",
      "_________________________________________________________________\n",
      "conv_pw_9_relu (Activation)  (None, 14, 14, 512)       0         \n",
      "_________________________________________________________________\n",
      "conv_pad_10 (ZeroPadding2D)  (None, 16, 16, 512)       0         \n",
      "_________________________________________________________________\n",
      "conv_dw_10 (DepthwiseConv2D) (None, 14, 14, 512)       4608      \n",
      "_________________________________________________________________\n",
      "conv_dw_10_bn (BatchNormaliz (None, 14, 14, 512)       2048      \n",
      "_________________________________________________________________\n",
      "conv_dw_10_relu (Activation) (None, 14, 14, 512)       0         \n",
      "_________________________________________________________________\n",
      "conv_pw_10 (Conv2D)          (None, 14, 14, 512)       262144    \n",
      "_________________________________________________________________\n",
      "conv_pw_10_bn (BatchNormaliz (None, 14, 14, 512)       2048      \n",
      "_________________________________________________________________\n",
      "conv_pw_10_relu (Activation) (None, 14, 14, 512)       0         \n",
      "_________________________________________________________________\n",
      "conv_pad_11 (ZeroPadding2D)  (None, 16, 16, 512)       0         \n",
      "_________________________________________________________________\n",
      "conv_dw_11 (DepthwiseConv2D) (None, 14, 14, 512)       4608      \n",
      "_________________________________________________________________\n",
      "conv_dw_11_bn (BatchNormaliz (None, 14, 14, 512)       2048      \n",
      "_________________________________________________________________\n",
      "conv_dw_11_relu (Activation) (None, 14, 14, 512)       0         \n",
      "_________________________________________________________________\n",
      "conv_pw_11 (Conv2D)          (None, 14, 14, 512)       262144    \n",
      "_________________________________________________________________\n",
      "conv_pw_11_bn (BatchNormaliz (None, 14, 14, 512)       2048      \n",
      "_________________________________________________________________\n",
      "conv_pw_11_relu (Activation) (None, 14, 14, 512)       0         \n",
      "_________________________________________________________________\n",
      "conv_pad_12 (ZeroPadding2D)  (None, 16, 16, 512)       0         \n",
      "_________________________________________________________________\n",
      "conv_dw_12 (DepthwiseConv2D) (None, 7, 7, 512)         4608      \n",
      "_________________________________________________________________\n",
      "conv_dw_12_bn (BatchNormaliz (None, 7, 7, 512)         2048      \n",
      "_________________________________________________________________\n",
      "conv_dw_12_relu (Activation) (None, 7, 7, 512)         0         \n",
      "_________________________________________________________________\n",
      "conv_pw_12 (Conv2D)          (None, 7, 7, 1024)        524288    \n",
      "_________________________________________________________________\n",
      "conv_pw_12_bn (BatchNormaliz (None, 7, 7, 1024)        4096      \n",
      "_________________________________________________________________\n",
      "conv_pw_12_relu (Activation) (None, 7, 7, 1024)        0         \n",
      "_________________________________________________________________\n",
      "conv_pad_13 (ZeroPadding2D)  (None, 9, 9, 1024)        0         \n",
      "_________________________________________________________________\n",
      "conv_dw_13 (DepthwiseConv2D) (None, 7, 7, 1024)        9216      \n",
      "_________________________________________________________________\n",
      "conv_dw_13_bn (BatchNormaliz (None, 7, 7, 1024)        4096      \n",
      "_________________________________________________________________\n",
      "conv_dw_13_relu (Activation) (None, 7, 7, 1024)        0         \n",
      "_________________________________________________________________\n",
      "conv_pw_13 (Conv2D)          (None, 7, 7, 1024)        1048576   \n",
      "_________________________________________________________________\n",
      "conv_pw_13_bn (BatchNormaliz (None, 7, 7, 1024)        4096      \n",
      "_________________________________________________________________\n",
      "conv_pw_13_relu (Activation) (None, 7, 7, 1024)        0         \n",
      "_________________________________________________________________\n",
      "global_average_pooling2d_3 ( (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "reshape_1 (Reshape)          (None, 1, 1, 1024)        0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 1, 1, 1024)        0         \n",
      "_________________________________________________________________\n",
      "conv_preds (Conv2D)          (None, 1, 1, 2)           2050      \n",
      "_________________________________________________________________\n",
      "act_softmax (Activation)     (None, 1, 1, 2)           0         \n",
      "_________________________________________________________________\n",
      "reshape_2 (Reshape)          (None, 2)                 0         \n",
      "=================================================================\n",
      "Total params: 3,230,338\n",
      "Trainable params: 3,208,450\n",
      "Non-trainable params: 21,888\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "mb_bnw.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.26113176345825195\n"
     ]
    }
   ],
   "source": [
    "st = time()\n",
    "mb_bnw.predict(np.random.rand(1,224,224,1))\n",
    "print(time() - st)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_submodel(main_model, output_layer = \"fc1\"):\n",
    "    return Model(inputs=main_model.inputs, output=main_model.get_layer(output_layer).output)\n",
    "mobile_net_submodel = get_submodel(mobile_net, \"global_average_pooling2d_1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.261125087738037\n"
     ]
    }
   ],
   "source": [
    "b = np.random.rand(16,112,112,3)\n",
    "st = time()\n",
    "mobile_net_new.predict(b)\n",
    "print(time() - st)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "No such layer: global_average_pooling2d_1",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-34-117d55e80083>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mmobile_net\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mMobileNet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mmobile_net_submodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_submodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmobile_net\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"global_average_pooling2d_1\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mversion\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdatetime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m16\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\" \"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"_\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"-\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"_\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\":\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"_\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-34-117d55e80083>\u001b[0m in \u001b[0;36mget_submodel\u001b[0;34m(main_model, output_layer)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mget_submodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmain_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_layer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"fc1\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmain_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmain_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_layer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_layer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mmobile_net\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mMobileNet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mmobile_net_submodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_submodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmobile_net\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"global_average_pooling2d_1\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/keras/engine/network.py\u001b[0m in \u001b[0;36mget_layer\u001b[0;34m(self, name, index)\u001b[0m\n\u001b[1;32m    363\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mlayer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    364\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 365\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'No such layer: '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    366\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    367\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: No such layer: global_average_pooling2d_1"
     ]
    }
   ],
   "source": [
    "def get_submodel(main_model, output_layer = \"fc1\"):\n",
    "    return Model(inputs=main_model.inputs, output=main_model.get_layer(output_layer).output)\n",
    "\n",
    "mobile_net = MobileNet()\n",
    "mobile_net_submodel = get_submodel(mobile_net, \"global_average_pooling2d_1\")\n",
    "\n",
    "version = str(datetime.now())[:16].replace(\" \", \"_\").replace(\"-\", \"_\").replace(\":\", \"_\")\n",
    "\n",
    "def read_image(image_path):\n",
    "    return cv2.imread(image_path)\n",
    "\n",
    "def resize_image(im_array, resolution = (224,224)):\n",
    "    return cv2.resize(im_array, resolution)\n",
    "\n",
    "def load_images(files_list):\n",
    "    return np.array([read_image(file) for file in files_list])\n",
    "\n",
    "def get_frames_video(video_path, resize_to = (224,224), output_frames = 16):\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    read_count = 1\n",
    "    frames_list = list()\n",
    "    frame_total = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "    while cap.isOpened():\n",
    "        isRead, frame = cap.read()\n",
    "        if not isRead: break\n",
    "        if read_count % (int(frame_total/output_frames) -1) == 0:\n",
    "            frame = cv2.resize(frame, resize_to)\n",
    "            frames_list.append(frame)\n",
    "        read_count += 1\n",
    "        if len(frames_list) == 16: break\n",
    "    return np.array(frames_list)\n",
    "\n",
    "def get_frame_features(frames_list):\n",
    "    # return mobile_net_submodel.predict(frames_list)\n",
    "    return np.array([np.squeeze(mobile_net_submodel.predict(np.expand_dims(frame, axis=0))) for frame in frames_list])\n",
    "\n",
    "def get_category(idx):\n",
    "    a = np.zeros(3)\n",
    "    a[idx] = 1\n",
    "    return a\n",
    "\n",
    "def prep_data(data_folder  = \"DataSets/KTH/train/\", recreate = False):\n",
    "    if recreate:\n",
    "        print(\"Recreating Data . . .\")\n",
    "        for folder in tqdm(os.listdir(data_folder)):\n",
    "            with open(\"LSTM_train_data/\" + folder+\".pkl\", \"wb\") as f:\n",
    "                pickle.dump({'folder': np.array([get_frame_features(get_frames_video(os.path.join(os.path.join(data_folder, folder), file))) for file in os.listdir(os.path.join(data_folder, folder))])}, f)\n",
    "            print(\"Created \" + \"LSTM_train_data/\" + folder+\".pkl\")\n",
    "        print(\"Done creating the necessary  files . . .\")\n",
    "        \n",
    "        classes = list(set(['walking', 'boxing', 'handwaving']))\n",
    "        class_id = dict([(cls, get_category(idx)) for idx, cls in enumerate(classes)])\n",
    "\n",
    "        with open(\"LSTM_train_data/class.pkl\", \"wb\") as f:\n",
    "            pickle.dump({\"classes\": classes, \"class_id\": class_id}, f)\n",
    "\n",
    "    trainX, trainY = list(), list()\n",
    "    with open(\"LSTM_train_data/class.pkl\", \"rb\") as f:\n",
    "        class_info = pickle.load(f)\n",
    "    classes = class_info[\"classes\"]\n",
    "    class_id = class_info[\"class_id\"]\n",
    "    \n",
    "    for cls, label in class_id.items():\n",
    "        with open(\"LSTM_train_data/\"+cls+\".pkl\", \"rb\") as f:\n",
    "            data_list = pickle.load(f)['folder']\n",
    "        for dl in data_list:\n",
    "            if dl.shape == (16,1024):\n",
    "                trainX.append(dl)\n",
    "                trainY.append(label)\n",
    "    trainX, trainY = np.array(trainX), np.array(trainY)\n",
    "    return classes, class_id, trainX, trainY\n",
    "\n",
    "def get_lstm_model(no_classes = 3, lstm_hidden_units = 200, image_features_size = 1024, step_size = 16, print_summary = False):\n",
    "    lstm_model = Sequential()\n",
    "    lstm_model.add(InputLayer(input_shape = (step_size, image_features_size)))\n",
    "    lstm_model.add(LSTM(lstm_hidden_units))\n",
    "    lstm_model.add(Dense(no_classes))\n",
    "    if print_summary: print(lstm_model.summary())\n",
    "    return lstm_model\n",
    "\n",
    "def train_model(lstm_model, trainX, trainY, epochs = 20, batch_size = 2, validation_split = 0.1):\n",
    "    lstm_model.compile(loss='mean_squared_error', optimizer='adam') #other losses\n",
    "    lstm_model.fit(trainX, trainY, epochs=epochs, batch_size=batch_size, validation_split=validation_split, shuffle=True, verbose=2)\n",
    "    os.mkdir(\"trained_models/\" + version)\n",
    "    lstm_model.save(\"trained_models/\" + version + \"/\" + version + \".hdf5\")\n",
    "    return lstm_model\n",
    "    \n",
    "def load_model(model_path = \"model_run_1.h5\"):\n",
    "    lstm_model = get_lstm_model()\n",
    "    lstm_model.load_weights(model_path)\n",
    "    return lstm_model\n",
    "                                      \n",
    "def model_predict(lstm_model, file_path, classes, get_class = False):\n",
    "    if get_class:\n",
    "        features = np.expand_dims(get_frame_features(get_frames_video(file_path)), axis=0)\n",
    "        st = time()\n",
    "        lstm_output = lstm_model.predict(features)\n",
    "        print(time() - st)\n",
    "        a =  classes[np.argmax(lstm_output)]\n",
    "        return a\n",
    "    else: return np.squeeze(lstm_model.predict(np.expand_dims(get_frame_features(get_frames_video(file_path)), axis=0))    )\n",
    "    \n",
    "def testfile_class(file_name):\n",
    "    return os.path.split(file_name)[-1].split(\"_\")[1]\n",
    "\n",
    "def train(no_classes = 3, lstm_hidden_units = 200, recreate_data = False):\n",
    "    lstm_model = get_lstm_model(no_classes = no_classes, lstm_hidden_units = lstm_hidden_units)\n",
    "    classes, class_id, trainX, trainY = prep_data(data_folder  = \"DataSets/KTH/train/\", recreate = recreate_data)\n",
    "    lstm_model = train_model(lstm_model, trainX, trainY, epochs = 40)\n",
    "    return lstm_model, classes, class_id\n",
    "\n",
    "def run_training():\n",
    "    lstm_model = train(lstm_hidden_units=200, recreate_data = False)\n",
    "\n",
    "def calc_precision_recall(n_classes, Y_test, y_score, version, plot = True):\n",
    "    # For each class\n",
    "    precision = dict()\n",
    "    recall = dict()\n",
    "    average_precision = dict()\n",
    "    \n",
    "    for i in range(n_classes):\n",
    "        precision[i], recall[i], _ = precision_recall_curve(Y_test[:, i],\n",
    "                                                            y_score[:, i])\n",
    "        average_precision[i] = average_precision_score(Y_test[:, i], y_score[:, i])\n",
    "    \n",
    "    # A \"micro-average\": quantifying score on all classes jointly\n",
    "    precision[\"micro\"], recall[\"micro\"], _ = precision_recall_curve(Y_test.ravel(), y_score.ravel())\n",
    "    average_precision[\"micro\"] = average_precision_score(Y_test, y_score, average=\"micro\")\n",
    "    print('Average precision score, micro-averaged over all classes: {0:0.2f}'.format(average_precision[\"micro\"]))\n",
    "    \n",
    "    if plot:\n",
    "        plt.figure()\n",
    "        plt.step(recall['micro'], precision['micro'], color='b', alpha=0.2,\n",
    "                 where='post')\n",
    "        plt.fill_between(recall[\"micro\"], precision[\"micro\"], alpha=0.2, color='b')\n",
    "\n",
    "        plt.xlabel('Recall')\n",
    "        plt.ylabel('Precision')\n",
    "        plt.ylim([0.0, 1.05])\n",
    "        plt.xlim([0.0, 1.0])\n",
    "        plt.title('Average precision score, micro-averaged over all classes: AP={0:0.2f}'.format(average_precision[\"micro\"]))\n",
    "        plt.savefig(\"trained_models/\" + version + \"/\" + version +\"_PR_curve.jpg\")\n",
    "        \n",
    "    return average_precision[\"micro\"], precision, recall, average_precision\n",
    "\n",
    "def test_model(version = \"2019_11_23_22_18\", test_classes_list = ['jogging', 'handclapping', 'running'], test_classes_dict = {'handclapping':1, 'jogging':2, 'running':2}, test_path = \"DataSets/KTH/test/*/*\", custom_name =\"\"):\n",
    "    lstm_trained_model = load_model(\"trained_models/\" + version + \"/\" + version +\".hdf5\")\n",
    "#     print(lstm_trained_model.summary())\n",
    "    lstm_model_sub = get_submodel(lstm_trained_model, 'lstm_1')\n",
    "    \n",
    "    test_results = dict()\n",
    "    for idx, i in enumerate(glob(test_path)):\n",
    "        try:\n",
    "            pred = model_predict(lstm_trained_model, i, test_classes_list, get_class = True)\n",
    "            features =  model_predict(lstm_model_sub, i, test_classes_list)\n",
    "            act = testfile_class(i)\n",
    "            test_results[idx] = {\"file\" : i, \"actual\" : act, \"prediction\" : pred, \"features\": features, \"pred_id\": test_classes_dict[pred], \"act_id\": test_classes_dict[act]}\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "            continue\n",
    "            \n",
    "    with open(\"trained_models/\" + version + \"/\" + version + custom_name + \".pkl\", \"wb\") as f:\n",
    "        pickle.dump(test_results, f)\n",
    "\n",
    "    results_df = pd.DataFrame.from_dict(test_results).transpose()\n",
    "    \n",
    "    Y_test = np.array([get_category(i) for i in np.array(results_df['act_id'])])\n",
    "    y_score = np.array([get_category(i) for i in np.array(results_df['pred_id'])])\n",
    "    \n",
    "    calc_precision_recall(3, Y_test, y_score, version, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.25221705436706543\n",
      "5.295051574707031\n",
      "0.008090496063232422\n",
      "4.464651584625244\n"
     ]
    }
   ],
   "source": [
    "test_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "CVIR_test_path = \"DataSets/Final_Data_Repo/*\"\n",
    "\n",
    "version = \"2019_11_23_22_18\"\n",
    "lstm_trained_model = load_model(\"trained_models/\" + version + \"/\" + version +\".hdf5\")\n",
    "#     print(lstm_trained_model.summary())\n",
    "lstm_model_sub = get_submodel(lstm_trained_model, 'lstm_1')\n",
    "\n",
    "# CVIR_test_videos_features = dict()\n",
    "# for fl in tqdm(glob(CVIR_test_path)):\n",
    "#     try:\n",
    "#         CVIR_test_videos_features[fl] = model_predict(lstm_model_sub, fl, [], get_class = False)\n",
    "#     except Exception as e:\n",
    "#         print(\"ERROR\", fl, e)\n",
    "#         continue\n",
    "        \n",
    "# print(len(CVIR_test_videos_features))\n",
    "# with open(\"repo.pkl\", \"wb\") as f:\n",
    "#     pickle.dump(CVIR_test_videos_features, f)\n",
    "\n",
    "with open(\"repo.pkl\", \"rb\") as f:\n",
    "    CVIR_test_videos_features = pickle.load(f)\n",
    "\n",
    "repo_dict = {'Covering' : 0, 'Uncovering' : 1, \"Pushing\": 2, \"Moving\" : 3, \"Poking\" : 4}\n",
    "\n",
    "repo_data = list()\n",
    "for fl, feat in CVIR_test_videos_features.items():\n",
    "    label = -1\n",
    "    for k in repo_dict.keys():\n",
    "        if k in fl:\n",
    "            label = repo_dict[k]\n",
    "            break\n",
    "    repo_data.append(np.array([feat, label]))\n",
    "\n",
    "repo_data = np.array(repo_data)\n",
    "repo_data_use, repo_data_test = repo_data[:80], repo_data[80:]\n",
    "\n",
    "def cosine_similarity(a,b):\n",
    "    return np.dot(a, b)/(np.linalg.norm(a)*np.linalg.norm(b))\n",
    "    \n",
    "def find_closest(test_array, threshold = 0.95):\n",
    "    close_list = list()\n",
    "    for idx, (feat, label) in enumerate(repo_data_use):\n",
    "        if cosine_similarity(feat, test_array) > threshold:\n",
    "            close_list.append([idx, label, cosine_similarity(feat, test_array)])\n",
    "    return close_list\n",
    "\n",
    "print(find_closest(repo_data_test[1][0]), \"\\n\\n\", repo_data_test[1][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 299/299 [15:21<00:00,  3.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "299\n",
      "[[2, 2, 0.96807516], [19, 2, 0.9588548], [21, 2, 0.9534637], [29, 1, 0.95916694], [32, 1, 0.98214936], [37, 1, 0.9900864], [40, 2, 0.97153825], [41, 2, 0.98444843], [43, 2, 0.9790073], [46, 1, 0.9510906], [47, 2, 0.97655475], [51, 2, 0.96483916], [55, 2, 0.977283], [56, 2, 0.9763586], [62, 1, 0.96223205], [64, 1, 0.9851486], [65, 1, 0.9854425], [67, 2, 0.97984725], [73, 2, 0.97161907], [74, 2, 0.97578615], [78, 1, 0.9793568]] \n",
      "\n",
      " 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "CVIR_test_path = \"DataSets/KTH/test/*/*\"\n",
    "\n",
    "version = \"2019_11_23_22_18\"\n",
    "lstm_trained_model = load_model(\"trained_models/\" + version + \"/\" + version +\".hdf5\")\n",
    "#     print(lstm_trained_model.summary())\n",
    "lstm_model_sub = get_submodel(lstm_trained_model, 'lstm_3')\n",
    "\n",
    "CVIR_test_videos_features = dict()\n",
    "for fl in tqdm(glob(CVIR_test_path)):\n",
    "    try:\n",
    "        CVIR_test_videos_features[fl] = model_predict(lstm_model_sub, fl, [], get_class = False)\n",
    "    except Exception as e:\n",
    "        print(\"ERROR\", fl, e)\n",
    "        continue\n",
    "        \n",
    "print(len(CVIR_test_videos_features))\n",
    "with open(\"test_ony.pkl\", \"wb\") as f:\n",
    "    pickle.dump(CVIR_test_videos_features, f)\n",
    "    \n",
    "repo_dict = {'handclapping' : 0, 'jogging' : 1, \"running\": 2}\n",
    "\n",
    "repo_data = list()\n",
    "for fl, feat in CVIR_test_videos_features.items():\n",
    "    label = -1\n",
    "    for k in repo_dict.keys():\n",
    "        if k in fl:\n",
    "            label = repo_dict[k]\n",
    "            break\n",
    "    repo_data.append(np.array([feat, label]))\n",
    "\n",
    "repo_data = np.array(repo_data)\n",
    "repo_data_use, repo_data_test = repo_data[:80], repo_data[80:]\n",
    "\n",
    "def cosine_similarity(a,b):\n",
    "    return np.dot(a, b)/(np.linalg.norm(a)*np.linalg.norm(b))\n",
    "    \n",
    "def find_closest(test_array, threshold = 0.95):\n",
    "    close_list = list()\n",
    "    for idx, (feat, label) in enumerate(repo_data_use):\n",
    "        if cosine_similarity(feat, test_array) > threshold:\n",
    "            close_list.append([idx, label, cosine_similarity(feat, test_array)])\n",
    "    return close_list\n",
    "\n",
    "print(find_closest(repo_data_test[1][0]), \"\\n\\n\", repo_data_test[1][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_accuracy(retrieved, index):\n",
    "    correct = 0\n",
    "    for i in retrieved[:,1]:\n",
    "        if repo_data_test[index][1] in [1,2] and i in [1,2]:\n",
    "            correct +=1\n",
    "        else:\n",
    "            if i == repo_data_test[index][1]:\n",
    "                correct += 1\n",
    "    return correct / len(retrieved)\n",
    "\n",
    "def retrieve(index):\n",
    "    retrieved = np.array(find_closest(repo_data_test[index][0], 0.85))\n",
    "    accuracy = check_accuracy(retrieved, index)\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for  0  is  0.8492067480548211\n",
      "Accuracy for  1  is  0.9217540665877051\n",
      "Accuracy for  2  is  0.9403554660252235\n"
     ]
    }
   ],
   "source": [
    "accuracy_dict = {0:[], 1:[], 2:[]}\n",
    "for i in range(len(repo_data_test)):\n",
    "    accuracy_dict[repo_data_test[i][1]].append(retrieve(i))\n",
    "    \n",
    "for k, v in accuracy_dict.items():\n",
    "    print(\"Accuracy for \", k, \" is \", sum(v)/len(v))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
