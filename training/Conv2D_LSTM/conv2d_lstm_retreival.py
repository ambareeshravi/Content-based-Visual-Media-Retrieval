# -*- coding: utf-8 -*-
"""train_Conv2D_LSTM.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1PkDPAH3SL8G8rZAnxOXj3SwFKS4XBQWI
"""

# imports
import warnings
warnings.filterwarnings('ignore')

import os, cv2, shutil, json
import numpy as np, pandas as pd, pickle as pkl

from glob import glob
from time import time
from datetime import datetime
from tqdm import tqdm

from sklearn.metrics import precision_recall_curve, average_precision_score, accuracy_score
from sklearn.metrics.pairwise import cosine_similarity, euclidean_distances
from sklearn.model_selection import train_test_split

from keras.applications.mobilenet import MobileNet
from keras.models import Model, load_model
from keras.layers import LSTM, Dense, InputLayer, Input
from keras.callbacks.callbacks import ModelCheckpoint
from keras.optimizers import Adam, SGD

class DataHandler:
	'''
	Handles all operations with respect to data
	'''
	def __init__(self, videos_path = "/content/drive/My drive/data/", test_size = 0.05):
		'''
		Initalizes the class variables for data handling
		'''
		self.n_frames = 16
		self.operating_resolution = (224, 224)
		self.test_split = test_size

		self.videos_path = videos_path
		self.image_feature_extractor = self.get_mobilenet_feature_extractor()
	
	def get_mobilenet_feature_extractor(self):
		'''
		Returns the mobilenet feature extractor
		'''
		mobilenet = MobileNet()
		return Model(inputs=mobilenet.inputs, output=mobilenet.get_layer("global_average_pooling2d_1").output)

	def sample_frames(self, video_path, to_normalize = True):
		'''
		Gets 'n' number of frames, each of resolution 'w' x 'h' and 3 channels (RGB) from a video

		Uses equidistant sampling of frames
		'''
		cap = cv2.VideoCapture(video_path)
		read_count = 1
		frames_list = list()
		frame_total = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))

		while cap.isOpened():
			isRead, frame = cap.read()
			if not isRead: break
			if read_count % (int(frame_total/self.n_frames)) == 0:
				frame = cv2.resize(frame, self.operating_resolution)
				if to_normalize: frame = frame.astype(np.float16) / 255.
				frames_list.append(frame)
			read_count += 1
			if len(frames_list) == self.n_frames: break
		return np.array(frames_list[:self.n_frames])

	def get_frame_features(self, frames):
		'''
		Returns features for each frame
		'''
		return np.squeeze(self.image_feature_extractor.predict(frames))

	def extract_video_features(self, video_file):
		'''
		Returns array of fram features for a video
		'''
		frames = self.sample_frames(video_file)
		return self.get_frame_features(frames)

	def prepare_training_data(self, videos_path):
		'''
		Returns data and labels for all videos in a directory
		'''
		folders = sorted(os.listdir(videos_path))
		classes = dict([(folder, idx) for idx, folder in enumerate(folders)])
		n_classes = len(classes)

		frame_features = list()
		labels = list()
		videos_list = list()

		for folder in folders:
			folder_path = os.path.join(self.videos_path, folder)
			video_files = sorted(glob(os.path.join(folder_path, "*")))

			for video_file in video_files:
				frame_features.append(self.extract_video_features(video_file))
				labels.append(classes[folder])
				videos_list.append(video_file)

		return np.array(frame_features), np.array(labels), np.array(videos_list), classes


	def get_training_data(self, save_data_as = None, data_pickle = None):
		'''
		Prepares the preprocessed training data and labels
		'''
		if data_pickle == None:
			if save_data_as == None: save_data_as = "conv2d_data.pkl"
			if ".pkl" not in save_data_as: save_data_as += ".pkl"

			X, y, video_list, classes = self.prepare_training_data(self.video_path)

			X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = self.test_split, random_state=42)

			pkl.dump({"X_train": X_train, "y_train": y_train, "X_test": X_test, "y_test": y_test, "classes": classes, "videos": video_list}, open(save_data_as, "wb"))
		else:
			data_dict = pkl.load(open(data_pickle, "rb"))
			X_train, y_train, X_test, y_test, video_list, classes = data_dict["X_train"], data_dict["y_train"], data_dict["X_test"], data_dict["y_test"], data_dict["videos"], data_dict["classes"]

		return X_train, X_test, y_train, y_test, video_list, classes

class Trainer(DataHandler):
	'''
	Handles all the training operations
	'''
	def __init__(self, data_to_use = "/content/drive/My Drive/data/KTH_data/KTH_HAR_C2DLSTM_train.pkl"):
		'''
		Initializes the training class variables
		'''
		DataHandler.__init__(self)
		# general
		self.training_version = str(datetime.now())[:16].replace("-", "_").replace(" ", "_")
		os.mkdir(self.training_version)
		save_data_as = None
		if data_to_use == None:
			save_data_as = os.path.split(model_path)[0] + "data.pkl"

		# data
		self.X_train, self.X_test, self.y_train, self.y_test, self.videos, self.classes = self.get_training_data(save_data_as = None, data_pickle = data_to_use)
		self.n_classes = len(self.classes)

		# model params
		self.lstm_hidden_units = 256
		self.image_features_size = 1024
		self.lstm_time_steps = 16

		# training params
		self.epochs = 25
		self.batch_size = 64
		self.validation_split = 0.1

	def get_lstm_model(self, print_summary = False):
		'''
		Creates and returns the LSTM model for training
		'''
		input_layer = Input(shape = (self.lstm_time_steps, self.image_features_size), name = 'input_layer')
		lstm1 = LSTM(self.lstm_hidden_units, name = 'lstm_1')(input_layer)
		dense1 = Dense(self.n_classes, activation = 'softmax')(lstm1)

		lstm_model = Model(inputs=input_layer, outputs=dense1)
		if print_summary: print(lstm_model.summary())
		return lstm_model

	def train(self, pretrained_model = None, model_path = None):
		'''
		Runs the training
		'''
		if pretrained_model != None: lstm_model = load_model(pretrained_model)
		else: lstm_model = self.get_lstm_model()

		if model_path == None: model_path = "CONV2D_LSTM_E{epoch:02d}.hdf5"
		model_path = os.path.join(self.training_version, model_path)

		callbacks = [ModelCheckpoint(model_path, monitor='val_accuracy', save_best_only=True, mode='max')]
		
		opt = Adam(learning_rate=0.01)
		lstm_model.compile(optimizer=opt, loss='sparse_categorical_crossentropy', metrics = ['accuracy'])
		lstm_model.fit(self.X_train, self.y_train, epochs=self.epochs, batch_size=self.batch_size, validation_split=self.validation_split, shuffle=True, verbose=2, callbacks = callbacks)

class Tester(DataHandler):
	'''
	Testing and evaluation for Conv2D  + LSTM mdeia retrieval model
	'''
	def __init__(self, test_model_path, test_data_path, distance_metric = "distance", lstm_output_layer = "lstm_1"):
		'''
		Initializes class variables for testing Conv2D + LSTM
		'''
		DataHandler.__init__(self)
		self.X_train, _, self.y_train, _, self.video_list, self.classes = self.get_training_data(save_data_as = None, data_pickle = test_data_path)
		# self.y_train = np.where(self.y_train==2, 1, self.y_train) 
        
		# load model
		# mobilenet = MobileNet()
		test_lstm_model = load_model(test_model_path)
		self.test_model = Model(inputs=test_lstm_model.inputs, output=test_lstm_model.get_layer(lstm_output_layer).output)
		if distance_metric == "similarity":
			self.distance = cosine_similarity
			self.distance_threshold = 0.8
			self.retrieve = self.retrieve_similar
		elif distance_metric == "distance":
			self.distance = euclidean_distances
			self.retrieve = self.retrieve_closest
			self.top = 50

	def retrieve_similar(self, row):
		return np.squeeze(np.argwhere(row > self.distance_threshold))

	def retrieve_closest(self, row, top = None):
		if top == None: top = self.top
		return np.argsort(row)[:top]

	def get_submodel(self, main_model, output_layer = "fc1"):
		return Model(inputs=main_model.inputs, output=main_model.get_layer(output_layer).output)

	def test(self):
		feature_vectors = self.test_model.predict(self.X_train, batch_size=32)
		distances = self.distance(feature_vectors, feature_vectors)
		for top in [5,10,20,50,75,100]:
			accuracy_list = list()
			for idx, row in enumerate(distances):
				retrieved_indexes = self.retrieve(row, top)
				try:
					retrieved_labels = self.y_train[retrieved_indexes]
					actual_labels = np.squeeze([self.y_train[idx]] * len(retrieved_labels))
					accuracy = accuracy_score(actual_labels, retrieved_labels)
					accuracy_list.append(accuracy)
				except:
					continue
			accuracy_list = np.array(accuracy_list)
			print("Top:", top, "Mean Retrieval Accuracy", np.mean(accuracy_list))

if __name__ == '__main__':
	# tr = Trainer()
	# tr.train()

	ts = Tester("/content/drive/My Drive/data/KTH_data/CONV2D_LSTM_E13.hdf5", "/content/drive/My Drive/data/KTH_data/KTH_HAR_C2DLSTM_test.pkl")
	ts.test()

